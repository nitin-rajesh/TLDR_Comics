{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "df412661",
      "metadata": {
        "id": "df412661"
      },
      "source": [
        "# GRU decoder for image captioning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGAE1c2t17l3",
        "outputId": "9a137172-4d88-4d7c-abb7-0c864a7d4154"
      },
      "id": "OGAE1c2t17l3",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Datasets')\n",
        "\n",
        "from img_caption import *"
      ],
      "metadata": {
        "id": "EmqhGYxL1-DD"
      },
      "id": "EmqhGYxL1-DD",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ddcda3fc",
      "metadata": {
        "id": "ddcda3fc"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from img_caption import *\n",
        "from torchvision import transforms\n",
        "from functools import partial\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e899f307",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e899f307",
        "outputId": "5020480e-3280-45b0-9372-dd21f39fa431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40455 30005\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "gec = GloveEmbeddingConverter('/content/drive/My Drive/Datasets/glove.6B.50d.txt')\n",
        "\n",
        "dataset = Flickr8kDataset(\n",
        "    image_dir=\"/content/drive/My Drive/Datasets/flickr8k/Images/\",\n",
        "    captions_file=\"/content/drive/My Drive/Datasets/flickr8k/captions.txt\",\n",
        "    glove_ec=gec,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "vocab_size = gec.get_vocab_size()\n",
        "print(len(dataset), vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=8, collate_fn=collate_fn_with_padding)\n",
        "hidden_dim = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = EncoderCNN(embed_size=gec.embedding_dim).to(device=device)\n",
        "decoder = FastDecoderGRU(embedding_dim=gec.embedding_dim, hidden_dim=hidden_dim,\n",
        "                     vocab_size=vocab_size, embeddings=gec.build_embedding_matrix()).to(device=device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(list(decoder.parameters()) + list(encoder.fc.parameters()), lr=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mbc5W73AW_z",
        "outputId": "8f5f0304-dfec-41b9-c6e2-330aa35555f1"
      },
      "id": "7mbc5W73AW_z",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/content/drive/My Drive/Datasets/img_caption/fast_gru.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.embedding.weight.data.copy_(torch.tensor(embeddings, dtype=torch.float))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.memory_summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NSs1lEuFJxX",
        "outputId": "3b4024f1-8f3e-42db-c772-f56aca96441c"
      },
      "id": "9NSs1lEuFJxX",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      | 110917 KiB | 110917 KiB | 111096 KiB | 183808 B   |\n",
            "|       from large pool |  92388 KiB |  92388 KiB |  92388 KiB |      0 B   |\n",
            "|       from small pool |  18528 KiB |  18590 KiB |  18708 KiB | 183808 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         | 110917 KiB | 110917 KiB | 111096 KiB | 183808 B   |\n",
            "|       from large pool |  92388 KiB |  92388 KiB |  92388 KiB |      0 B   |\n",
            "|       from small pool |  18528 KiB |  18590 KiB |  18708 KiB | 183808 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      | 110313 KiB | 110313 KiB | 110491 KiB | 182400 B   |\n",
            "|       from large pool |  91821 KiB |  91821 KiB |  91821 KiB |      0 B   |\n",
            "|       from small pool |  18492 KiB |  18553 KiB |  18670 KiB | 182400 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   | 135168 KiB | 135168 KiB | 135168 KiB |      0 B   |\n",
            "|       from large pool | 114688 KiB | 114688 KiB | 114688 KiB |      0 B   |\n",
            "|       from small pool |  20480 KiB |  20480 KiB |  20480 KiB |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |  24251 KiB |  28795 KiB |  88281 KiB |  64030 KiB |\n",
            "|       from large pool |  22299 KiB |  28160 KiB |  74496 KiB |  52196 KiB |\n",
            "|       from small pool |   1951 KiB |   2071 KiB |  13785 KiB |  11833 KiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     329    |     331    |     333    |       4    |\n",
            "|       from large pool |      19    |      19    |      19    |       0    |\n",
            "|       from small pool |     310    |     313    |     314    |       4    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     329    |     331    |     333    |       4    |\n",
            "|       from large pool |      19    |      19    |      19    |       0    |\n",
            "|       from small pool |     310    |     313    |     314    |       4    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      16    |      16    |      16    |       0    |\n",
            "|       from large pool |       6    |       6    |       6    |       0    |\n",
            "|       from small pool |      10    |      10    |      10    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       8    |      10    |      17    |       9    |\n",
            "|       from large pool |       5    |       5    |       5    |       0    |\n",
            "|       from small pool |       3    |       5    |      12    |       9    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "for epoch in range(10):\n",
        "    for idx, (imgs, captions) in enumerate(tqdm(data_loader,desc=\"Training progress \",leave=True)):\n",
        "\n",
        "        imgs, captions = imgs.to(device), captions.to(device)\n",
        "        with torch.no_grad():\n",
        "          features = encoder(imgs)\n",
        "        hidden = torch.zeros(1, features.size(0), hidden_dim).to(features.device)\n",
        "        predictions, _ = decoder(captions[:, :-1], hidden)  # Input sequence excluding <EOS>\n",
        "        target = captions[:, 1:]                   # Target sequence excluding <SOS>\n",
        "        loss = criterion(predictions.view(-1, vocab_size), target.reshape(-1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print(torch.cuda.memory_summary())\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}\")\n",
        "    # Save everything in one checkpoint\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'encoder_state_dict': encoder.state_dict(),\n",
        "        'decoder_state_dict': decoder.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss.item(),\n",
        "    }, 'checkpoint.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auuXkjCRAeM0",
        "outputId": "6a665b29-1531-4392-95d8-978a3af2e38f"
      },
      "id": "auuXkjCRAeM0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress : 100%|██████████| 1265/1265 [05:51<00:00,  3.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 3.2475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress : 100%|██████████| 1265/1265 [05:30<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 3.3767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress : 100%|██████████| 1265/1265 [05:27<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 3.0532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress : 100%|██████████| 1265/1265 [05:24<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 2.7555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress : 100%|██████████| 1265/1265 [05:24<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 3.1134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress : 100%|██████████| 1265/1265 [05:26<00:00,  3.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 2.7778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress : 100%|██████████| 1265/1265 [05:26<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 2.4197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress : 100%|██████████| 1265/1265 [05:28<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 2.4746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress : 100%|██████████| 1265/1265 [05:22<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 3.6285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress :  81%|████████  | 1027/1265 [04:27<00:52,  4.49it/s]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}